{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttdy9D0k1ycm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_FeN-Ep4Rpp"
      },
      "source": [
        "Install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk0qUhJUQrkO",
        "outputId": "3b92ab47-b18b-4b6b-bead-81658c390f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install -q cassio datasets langchain openai tiktoken\n",
        "%pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSQU7Xfj5Bub",
        "outputId": "28ed9e2c-e80e-4389-d6f2-7dbda37c06b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/132.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255315 sha256=8a58f98ab88ebadc376709cb95fc906e3e703b9e60099f972e1cfd91a1da5a4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ],
      "source": [
        "%pip install pickle5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQN-L2J4Rpq"
      },
      "source": [
        "Import the packages you'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V4qBIihE4Rpq"
      },
      "outputs": [],
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import gensim\n",
        "import pickle5 as pickle\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIs76OPQ6JyD",
        "outputId": "352981a8-fcc8-434b-c8e3-af1a061346ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1itBNL1v6N9-"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2UauiC4Rpr"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "waVKJW-n6jqJ"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('short_story.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "42BKuFRO6meP"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vR41Iq-4ZHnG",
        "outputId": "b573afed-c94f-42cc-d57c-307c36c04146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nwww.britishcouncil.org/learnenglishkids  \\n© British Council, 201 7 The United Kingdom’s international organisation for educational opportunities and cultural relations. We are registered in En gland as a charity.   \\nLittle Red Riding Hood   Short story  \\nLittle Red Riding Hood lived in a wood with her mother. One \\nday Little Red Riding Hood went to visit her granny. She had \\na nice cake in her basket.  \\n \\nOn her way Little Red Riding Hood met a wolf.  \\n‘Hello!’ said the wolf. ‘Where are you going?’   \\n \\n‘I’m going to see my grandmother. She lives in a house behind those trees.’  \\n \\nThe wolf ran to Granny’s house and ate Granny up. He got into Granny’s bed. A little \\nlater, Little Red Riding Hood reached the house. She looked at the wolf.  \\n \\n‘Granny, what big eyes y ou have!’  \\n‘All the better to see you with!’ said the wolf.  \\n \\n‘Granny, what big ears you have!’  \\n‘All the better to hear you with!’ said the wolf.  \\n \\n‘Granny, what a big nose you have!’  \\n‘All the better to smell you with!’ said the wolf.  \\n \\n‘Granny, what big teeth you have!’  \\n‘All the better to eat you with!’ shouted the wolf.  \\n \\nA woodcutter was in the wood. He heard a loud scream and ran to the house.  \\n \\nThe woodcutter hit the wolf over the head. The wolf opened his mouth wide and \\nshouted and Granny jumped out.  \\n \\nThe wolf ran away and Little Red Riding Hood never saw the wolf again.  \\n \\n \\nListen to this story  https://learnenglishkids.britishcouncil.org/en/short -stori es/little -red-riding -hood   \\n \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S0GgIQs4Rps"
      },
      "source": [
        "Initialize the connection to your database:\n",
        "\n",
        "_(do not worry if you see a few warnings, it's just that the drivers are chatty about negotiating protocol versions with the DB.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FMAhKr77AVO",
        "outputId": "6be2888a-34a2-49cc-fe3b-f0aacf31fffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 14, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 148, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 43, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 97, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 57, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 35, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 49, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 25, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 61, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 40, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 54, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 25, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 58, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 23, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 89, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 89, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 92, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 92, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 33, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 44, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 46, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 66, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 74, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 53, which is longer than the specified 10\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 14, which is longer than the specified 10\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \".\",\n",
        "    chunk_size = 10,\n",
        "    chunk_overlap  = 5,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BDHAyT7Gjr",
        "outputId": "33f6a492-2368-4953-c5d4-fff8972baa9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['www',\n",
              " 'britishcouncil',\n",
              " 'org/learnenglishkids  \\n© British Council, 201 7 The United Kingdom’s international organisation for educational opportunities and cultural relations',\n",
              " 'We are registered in En gland as a charity',\n",
              " 'Little Red Riding Hood   Short story  \\nLittle Red Riding Hood lived in a wood with her mother',\n",
              " 'One \\nday Little Red Riding Hood went to visit her granny',\n",
              " 'She had \\na nice cake in her basket',\n",
              " 'On her way Little Red Riding Hood met a wolf',\n",
              " '‘Hello!’ said the wolf',\n",
              " '‘Where are you going?’   \\n \\n‘I’m going to see my grandmother',\n",
              " 'She lives in a house behind those trees',\n",
              " '’  \\n \\nThe wolf ran to Granny’s house and ate Granny up',\n",
              " 'He got into Granny’s bed',\n",
              " 'A little \\nlater, Little Red Riding Hood reached the house',\n",
              " 'She looked at the wolf',\n",
              " '‘Granny, what big eyes y ou have!’  \\n‘All the better to see you with!’ said the wolf',\n",
              " '‘Granny, what big ears you have!’  \\n‘All the better to hear you with!’ said the wolf',\n",
              " '‘Granny, what a big nose you have!’  \\n‘All the better to smell you with!’ said the wolf',\n",
              " '‘Granny, what big teeth you have!’  \\n‘All the better to eat you with!’ shouted the wolf',\n",
              " 'A woodcutter was in the wood',\n",
              " 'He heard a loud scream and ran to the house',\n",
              " 'The woodcutter hit the wolf over the head',\n",
              " 'The wolf opened his mouth wide and \\nshouted and Granny jumped out',\n",
              " 'The wolf ran away and Little Red Riding Hood never saw the wolf again',\n",
              " 'Listen to this story  https://learnenglishkids',\n",
              " 'britishcouncil',\n",
              " 'org/en/short -stori es/little -red-riding -hood']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ecxH8GFOn0J9"
      },
      "outputs": [],
      "source": [
        "# Remove '\\n' from each chunk of text\n",
        "cleaned_texts = [chunk.replace('\\n', '') for chunk in texts]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xe6YaAGWkhJb",
        "outputId": "d59a7e2f-f6c1-481f-d5fc-4fec0d1b6f3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'org/learnenglishkids  © British Council, 201 7 The United Kingdom’s international organisation for educational opportunities and cultural relations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "cleaned_texts[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JZORs4pG2PRQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert words in each chunk into vectors\n",
        "def words_to_vectors(texts):\n",
        "    # Initialize TF-IDF Vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Tokenize each chunk into words and fit TF-IDF Vectorizer\n",
        "    tfidf_vectorizer.fit(texts)\n",
        "\n",
        "    # Transform each word into a vector\n",
        "    word_vectors = tfidf_vectorizer.transform(texts)\n",
        "\n",
        "    return word_vectors, tfidf_vectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qR1GCRFE2Xv_"
      },
      "outputs": [],
      "source": [
        "# Store vectors in a file using pickle\n",
        "def save_vectors_to_file(text_vectors, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(text_vectors, f)\n",
        "\n",
        "# Load vectors from a file\n",
        "def load_vectors_from_file(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        text_vectors = pickle.load(f)\n",
        "    return text_vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KpOPmooNJzlN"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pickle\n",
        "\n",
        "\n",
        "word_vectors, tfidf_vectorizer = words_to_vectors(cleaned_texts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq67DWbUeMd1",
        "outputId": "2962a321-da1a-48c0-b4b1-90bd26b2c0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: trees, Importance: 0.41876224069471213\n",
            "Word: those, Importance: 0.41876224069471213\n",
            "Word: she, Importance: 0.33899876346111957\n",
            "Word: lives, Importance: 0.41876224069471213\n",
            "Word: in, Importance: 0.2923401203523422\n",
            "Word: house, Importance: 0.3133206591937176\n",
            "Word: behind, Importance: 0.41876224069471213\n"
          ]
        }
      ],
      "source": [
        "# Example usage to see the importance of every word in a chunk\n",
        "chunk_index = 10  # Index of the chunk for which you want to see word importance\n",
        "\n",
        "# Get TF-IDF weights for the specified chunk\n",
        "tfidf_weights_chunk = word_vectors[chunk_index]\n",
        "\n",
        "# Get the feature names (words) from the TF-IDF Vectorizer\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dictionary to store word importance\n",
        "word_importance = {}\n",
        "\n",
        "# Iterate over each word index and its corresponding TF-IDF weight\n",
        "for word_index, tfidf_weight in zip(tfidf_weights_chunk.indices, tfidf_weights_chunk.data):\n",
        "    # Get the word corresponding to the index\n",
        "    word = feature_names[word_index]\n",
        "    # Store the TF-IDF weight of the word in the dictionary\n",
        "    word_importance[word] = tfidf_weight\n",
        "\n",
        "# Print word importance\n",
        "for word, importance in word_importance.items():\n",
        "    print(f\"Word: {word}, Importance: {importance}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6RfS7Nv-o0rL"
      },
      "outputs": [],
      "source": [
        "def question_to_vector(question, tfidf_vectorizer):\n",
        "    # Transform the question into a TF-IDF vector\n",
        "    question_vector = tfidf_vectorizer.transform([question])\n",
        "    return question_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE7yzPPcicug",
        "outputId": "67a94be1-3e32-43df-d2fb-4f6c8939a2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar chunk to answer the question: ‘Where are you going?’   \n",
            " \n",
            "‘I’m going to see my grandmother\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Similarity score for chunk 10: 0.7155414938921723\n",
            "Chunk 10: ‘Where are you going?’   \n",
            " \n",
            "‘I’m going to see my grandmother\n",
            "\n",
            "Similarity score for chunk 9: 0.20036322481096547\n",
            "Chunk 9: ‘Hello!’ said the wolf\n",
            "\n",
            "Similarity score for chunk 16: 0.14893659466678966\n",
            "Chunk 16: ‘Granny, what big eyes y ou have!’  \n",
            "‘All the better to see you with!’ said the wolf\n",
            "\n",
            "Similarity score for chunk 18: 0.14357153016191224\n",
            "Chunk 18: ‘Granny, what a big nose you have!’  \n",
            "‘All the better to smell you with!’ said the wolf\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define the question\n",
        "# Where did little red riding hood live\n",
        "# what did red riding hood had in her basket\n",
        "# where was the wood cutter\n",
        "# red riding hood whom did she meet on her way\n",
        "# wher did the woodcutter hit the wolf\n",
        "# what happened when the wolf opened his mouth\n",
        "# what did woodcutter do when he heard a loud scream\n",
        "question = \"\"\n",
        "\n",
        "# Convert the question into a vector using TF-IDF\n",
        "question_vector = question_to_vector(question, tfidf_vectorizer)\n",
        "\n",
        "# Calculate cosine similarity between question vector and text vectors\n",
        "similarities = cosine_similarity(question_vector, word_vectors)\n",
        "\n",
        "# Find the index of the most similar chunk\n",
        "most_similar_index = np.argmax(similarities)\n",
        "\n",
        "# Retrieve the most similar chunk\n",
        "most_similar_chunk = texts[most_similar_index]\n",
        "\n",
        "print(\"Most similar chunk to answer the question:\", most_similar_chunk)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "# Calculate cosine similarity for the first 4 chunks\n",
        "# Sort similarity scores and retrieve indices of top 4 chunks\n",
        "top_indices = np.argsort(similarities, axis=1)[0][-4:][::-1]\n",
        "\n",
        "# Print the similarity scores and corresponding chunks for the top 4 chunks\n",
        "for idx in top_indices:\n",
        "    similarity_score = similarities[0][idx]\n",
        "    chunk = texts[idx]\n",
        "    print(f\"Similarity score for chunk {idx + 1}: {similarity_score}\")\n",
        "    print(f\"Chunk {idx + 1}: {chunk}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxkhsJX8gAkb",
        "outputId": "9923922e-6465-4ddf-a9ab-94c8a521be50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF value for the word at index 111: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the TF-IDF value for the word at index 111 in the sparse matrix representation\n",
        "tfidf_value = word_vectors[0, 111]\n",
        "print(\"TF-IDF value for the word at index 111:\", tfidf_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSaUPguw389l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}